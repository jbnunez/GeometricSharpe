{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import quandl\n",
    "import datetime\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "quandl.ApiConfig.api_key = \"63gdVnc_-LzW9XyB1Ajk\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of potential stocks to invest in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stocksymlist = [\"MSFT\", \"AXP\", \"BA\", \"CAT\", \"CVX\", \"CSCO\", \"KO\", \"DIS\",  \"XOM\", \"GE\", \"GS\",\n",
    "                \"HD\", \"IBM\", \"JNJ\", \"JPM\", \"MCD\", \"MRK\", \"NKE\", \"PFE\", \"PG\", \"UTX\", \"UNH\", \"VZ\",\n",
    "                \"V\", \"WMT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017-03-25'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years_back = 1\n",
    "tnow = date.today()\n",
    "enddate = tnow.isoformat()\n",
    "startyear = tnow.year - years_back\n",
    "sd = tnow.replace(year=startyear)\n",
    "#startmonth = tnow.month - 1\n",
    "#startday = tnow.day + 1\n",
    "#sd = tnow.replace(day=startday, month=startmonth)\n",
    "startdate = sd.isoformat()\n",
    "startdate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the asset data from quandl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assets = []\n",
    "for stocksym in stocksymlist:\n",
    "    stocksymlo = stocksym.lower()\n",
    "    stocksymup = stocksym.upper()\n",
    "    stocksym = stocksymlo\n",
    "    quandlstock = str(\"WIKI/\")\n",
    "    quandlstock = quandlstock + stocksymup\n",
    "    stock = quandl.get(quandlstock, start_date=startdate, end_date=enddate)\n",
    "    assets.append(stock)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add continuous growth rates to stock info and calculate risk level (sigma) and return rate (drift).  Also, create a list of cgrs, which we'll use to calculate covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigmas = []\n",
    "drifts = []\n",
    "cgrs = []\n",
    "for stock in assets:\n",
    "    price = np.array(stock.Close)\n",
    "    pricep1 = np.roll(price,1)\n",
    "    lnratio = price/pricep1\n",
    "    cgr = np.log(lnratio)\n",
    "    cgr[0]=999.99\n",
    "    stock['cgr'] = cgr\n",
    "    stock = stock[['Close','Volume','cgr']]\n",
    "    \n",
    "    sigma = np.std(cgr[1:])\n",
    "    sigmas.append(sigma)\n",
    "    drift = np.mean(cgr[1:])\n",
    "    drifts.append(drift)\n",
    "    cgrs.append(cgr[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Put cgrs in numpy array and calculate covariances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgrs = np.array(cgrs)\n",
    "covmat = np.cov(cgrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to normalize weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_weights(weights):\n",
    "    total = np.sum(weights)\n",
    "    return weights/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to calculate risk for a portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def risk(weights):\n",
    "    sig_sq = float(0)\n",
    "    for i in range(len(weights)):\n",
    "        for j in range(len(weights)):\n",
    "            sig_sq += weights[i]*weights[j]*covmat[i][j]\n",
    "    return sig_sq**0.5\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to calculate return of portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_rate(weights):\n",
    "    rate = float(0)\n",
    "    for i in range(len(weights)):\n",
    "        rate += weights[i]*drifts[i]\n",
    "    return rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KL Divergence function.  For two normal distributions with std devs $\\sigma_1$ and $\\sigma_2$ and means $\\mu_1$ and $\\mu_2$, the KL Divergence is\n",
    "\n",
    "$KL = \\log\\frac{\\sigma_2}{\\sigma_1} + \\frac{\\sigma_1^2 + (\\mu_1 - \\mu_2)^2}{2\\sigma_2^2} - \\frac{1}{2}$\n",
    "\n",
    "In our function the first term will be called $a$ and the second term $b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def KL(p_rate, p_sig, q_rate, q_sig):\n",
    "    a = np.log(q_sig/p_sig)\n",
    "    b = (p_sig**2 + (p_rate-q_rate)**2)/(2*q_sig**2)\n",
    "    return a + b - 0.5\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to find an upper limit on how good our sharpe ratio can be.  The best return we can have is simply the max of the returns of the individual assets.  The lowest risk is somewhat more difficult to find.  The risk is trickier to find, since the risk is lowered by diversification.  However, an evenly distributed portfolio is a good guess for the minimal risk, since that at least minimizes the $\\pi_i \\pi_j$ term in the summation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_rate = max(drifts)\n",
    "safe_weights = np.array([1.0/len(assets) for i in range(len(assets))])*4\n",
    "target_risk = risk(safe_weights)/4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the formula we calculated for the partial of the divergence with respect to a weight\n",
    "\n",
    "$\\frac{\\partial KL(p,q)}{\\partial \\pi_i} =  - \\frac{\\sum_{j=1}^n \\pi_j \\text{Cov} (R_i, R_j)}{2\\sum_{i,j=1}^n \\pi_i \\pi_j \\text{Cov} (R_i, R_j)} \n",
    " + \\frac{\\sum_{j=1}^n \\pi_j \\text{Cov} (R_i, R_j)}{2\\sigma_2^2} + \\frac{r_j (\\sum_{j=1}^n \\pi_j r_j - \\mu_2)}{\\sigma_2^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now here are some functions to help find the gradient of the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weighted_cov_sum(i, weights):\n",
    "    wsum = float(0)\n",
    "    for j in range(len(weights)):\n",
    "        if j==i:\n",
    "            wsum += 2*weights[i]*covmat[i][i]\n",
    "        else:\n",
    "            wsum += weights[j]*covmat[i][j]\n",
    "    return wsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient(weights):\n",
    "    sig1 = risk(weights)\n",
    "    mu1 = return_rate(weights)\n",
    "    grad = np.zeros(len(weights))\n",
    "    for i in range(len(grad)):\n",
    "        wsum = weighted_cov_sum(i, weights)\n",
    "        grad[i] = (wsum/(2*(target_risk**2))) + ((drifts[i]*mu1)/(target_risk**2)) - (wsum/(2*(sig1**2)))\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the bit of code that does the gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0665924056286\n",
      "0.0496012387644\n",
      "0.0496012387644\n",
      "0.0496012387644\n",
      "0.0496012387644\n",
      "0.0496012387644\n",
      "0.0496012387644\n",
      "0.0496012387644\n",
      "0.0496012387644\n",
      "0.0496012387644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.05309086,  0.05216694,  0.07933059,  0.07540222,  0.03583917,\n",
       "         0.05614521,  0.01931915,  0.02769312,  0.02437967,  0.00270538,\n",
       "         0.05588938,  0.04820473,  0.02596953,  0.02915392,  0.05396609,\n",
       "         0.03437528,  0.01628248,  0.04795217,  0.03395631,  0.01372702,\n",
       "         0.0397458 ,  0.04894376,  0.03356956,  0.04892027,  0.04327139]),\n",
       " 0.049601238764434563)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def optimize_sharpe(epochs, learn_rate):\n",
    "    #initialize and normalize weights\n",
    "    weights = np.random.normal(loc=0.5, scale=0.1, size=len(assets))\n",
    "    weights = weights/np.sum(weights)\n",
    "    last_error = float(\"inf\")\n",
    "    for epoch in range(epochs):\n",
    "        #get a new set of samples\n",
    "        xbatch = next_batch()\n",
    "        \n",
    "        #normalize the weights\n",
    "        if np.min(weights)<0:\n",
    "            weights = weights - np.min(weights)\n",
    "        weights = weights/np.sum(weights)\n",
    "        \n",
    "        #take stddev and mean of predictions\n",
    "        pred_sig = risk(weights)\n",
    "        pred_rate = return_rate(weights)\n",
    "        \n",
    "        #compare to target using KL div\n",
    "        error = KL(pred_rate, pred_sig, target_rate, target_risk)\n",
    "        \n",
    "        #get gradient for these weights\n",
    "        grad = gradient(weights)\n",
    "        \n",
    "        #update weights\n",
    "        weights += error*grad*learn_rate\n",
    "        \n",
    "        #change learning rate\n",
    "        if error/last_error > 1.04:\n",
    "            learn_rate *= 0.7\n",
    "        elif error < last_error:\n",
    "            learn_rate *= 1.05\n",
    "        \n",
    "        last_error = error\n",
    "            \n",
    "        if epoch%1000 == 0:\n",
    "            print(error)\n",
    "    \n",
    "    if np.min(weights)<0:\n",
    "        weights = weights-np.min(weights)\n",
    "    weights = weights/np.sum(weights)\n",
    "    #norm_weights = weights/np.sum(weights)\n",
    "\n",
    "    return (weights, error)\n",
    "\n",
    "(proportions, error) = optimize_sharpe(10000, 0.001)\n",
    "(proportions, error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that proportions add up to one.  Note that negative coefficients mean that you should be shorting that asset.  Since you gain capital from short selling a stock, it doesn't matter that the absolute values of all the assets exceeds 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(proportions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the optimal set of investments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portion of portfolio allocated to each asset:\n",
      "MSFT:  0.0530908605688\n",
      "AXP:  0.0521669411439\n",
      "BA:  0.0793305866345\n",
      "CAT:  0.0754022233442\n",
      "CVX:  0.0358391733146\n",
      "CSCO:  0.0561452095357\n",
      "KO:  0.0193191515018\n",
      "DIS:  0.0276931177897\n",
      "XOM:  0.0243796745766\n",
      "GE:  0.00270537708667\n",
      "GS:  0.0558893789151\n",
      "HD:  0.0482047347027\n",
      "IBM:  0.0259695296038\n",
      "JNJ:  0.029153920617\n",
      "JPM:  0.0539660916195\n",
      "MCD:  0.0343752788249\n",
      "MRK:  0.0162824754119\n",
      "NKE:  0.0479521664225\n",
      "PFE:  0.0339563077635\n",
      "PG:  0.0137270249858\n",
      "UTX:  0.0397457950647\n",
      "UNH:  0.0489437581202\n",
      "VZ:  0.0335695633777\n",
      "V:  0.048920265631\n",
      "WMT:  0.0432713934432\n",
      "Daily risk:  1.00701214877  standard deviation in daily return\n",
      "Daily return:  1.00087023885  daily return\n",
      "Daily Sharpe =  0.993900858167\n",
      "Yearly risk:  11.7312165914  standard deviation in percent return\n",
      "Yearly return:  24.5086274145  expected yearly percent return\n"
     ]
    }
   ],
   "source": [
    "print(\"Portion of portfolio allocated to each asset:\")\n",
    "for i in range(len(assets)):\n",
    "    print(stocksymlist[i] + \": \", proportions[i])\n",
    "      \n",
    "portfolio_risk = np.exp(risk(proportions))\n",
    "portfolio_rate = np.exp(return_rate(proportions))\n",
    "print(\"Daily risk: \", portfolio_risk, \" standard deviation in daily return\")\n",
    "print(\"Daily return: \", portfolio_rate, \" daily return\")\n",
    "print(\"Daily Sharpe = \", portfolio_rate/portfolio_risk)\n",
    "\n",
    "yearly_risk = 100*np.exp((252**0.5)*risk(proportions))-100\n",
    "yearly_return = 100*np.exp(252*return_rate(proportions))-100\n",
    "\n",
    "print(\"Yearly risk: \", yearly_risk, \" standard deviation in percent return\")\n",
    "print(\"Yearly return: \", yearly_return, \" expected yearly percent return\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this may seem like an unusually high rate of return, the past year did see a boom in the stock market.  It is also a feasible value, as the fastest growing stock among those we considered grew at a rate of over 100 percent in the past year, as we can see below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0123361767928309"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(target_rate*250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, it makes sense that the benefits of diversification are minimal since there was a booming market and therefore highly correlated stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll print out the risk and return for each of the assets we considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asset Yearly return Yearly risk\n",
      "MSFT 1.00152853019 1.01119876735 0.990436858239\n",
      "AXP 1.00082632549 1.01058993132 0.990338706606\n",
      "BA 1.00280110107 1.01383942912 0.989112350796\n",
      "CAT 1.00194260151 1.01409893402 0.988012675988\n",
      "CVX 1.00000399728 1.01123720115 0.988891623188\n",
      "CSCO 1.00109627513 1.01209290113 0.989134766204\n",
      "KO 1.00011737216 1.0070293243 0.993136295065\n",
      "DIS 0.999707412881 1.01141320008 0.988426305685\n",
      "XOM 0.999651547448 1.00911555271 0.990621485088\n",
      "GE 0.996957337389 1.01546763452 0.981771652293\n",
      "GS 1.00019039773 1.01368941688 0.986683278999\n",
      "HD 1.00090181088 1.01072615221 0.990279917756\n",
      "IBM 0.999405461088 1.01149223277 0.988050554134\n",
      "JNJ 1.00019392648 1.00940911361 0.990870711387\n",
      "JPM 1.00095132885 1.01092512801 0.990133988273\n",
      "MCD 1.0008473959 1.00961043852 0.991320372412\n",
      "MRK 0.999203574821 1.01098835987 0.988343302931\n",
      "NKE 1.00069135708 1.01511032077 0.985795668316\n",
      "PFE 1.00026843774 1.00925554652 0.991095309004\n",
      "PG 0.999432383339 1.00787362727 0.991624700056\n",
      "UTX 1.00074154002 1.0105089121 0.990334204916\n",
      "UNH 1.00120191934 1.01094868028 0.990358797498\n",
      "VZ 0.999857773561 1.01182149791 0.988176052426\n",
      "V 1.00131137183 1.00980748569 0.991586402377\n",
      "WMT 1.00103014162 1.01388136797 0.987324723823\n",
      "Best sharpe of individual stock:  0.993136295065\n",
      "Our Sharpe:  0.993900858167\n"
     ]
    }
   ],
   "source": [
    "print(\"Asset\", \"Yearly return\", \"Yearly risk\")\n",
    "best_sharpe = float(0)\n",
    "for i in range(len(assets)):\n",
    "    sharpe = np.exp(drifts[i])/np.exp(sigmas[i])\n",
    "    if sharpe > best_sharpe:\n",
    "        best_sharpe = sharpe\n",
    "    print(stocksymlist[i], np.exp(drifts[i]), np.exp(sigmas[i]), sharpe)\n",
    "print(\"Best sharpe of individual stock: \", best_sharpe)\n",
    "print(\"Our Sharpe: \", portfolio_rate/portfolio_risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
