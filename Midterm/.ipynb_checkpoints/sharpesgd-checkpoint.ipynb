{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import quandl\n",
    "import datetime\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "quandl.ApiConfig.api_key = \"63gdVnc_-LzW9XyB1Ajk\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of potential stocks to invest in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stocksymlist = [\"MSFT\", \"AXP\", \"BA\", \"CAT\", \"CVX\", \"CSCO\", \"KO\", \"DIS\",  \"XOM\", \"GE\", \"GS\",\n",
    "                \"HD\", \"IBM\", \"JNJ\", \"JPM\", \"MCD\", \"MRK\", \"NKE\", \"PFE\", \"PG\", \"UTX\", \"UNH\", \"VZ\",\n",
    "                \"V\", \"WMT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017-02-28'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years_back = 1\n",
    "tnow = date.today()\n",
    "enddate = tnow.isoformat()\n",
    "startyear = tnow.year - years_back\n",
    "sd = tnow.replace(year=startyear)\n",
    "#startmonth = tnow.month - 1\n",
    "#startday = tnow.day + 1\n",
    "#sd = tnow.replace(day=startday, month=startmonth)\n",
    "startdate = sd.isoformat()\n",
    "startdate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the asset data from quandl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assets = []\n",
    "for stocksym in stocksymlist:\n",
    "    stocksymlo = stocksym.lower()\n",
    "    stocksymup = stocksym.upper()\n",
    "    stocksym = stocksymlo\n",
    "    quandlstock = str(\"WIKI/\")\n",
    "    quandlstock = quandlstock + stocksymup\n",
    "    stock = quandl.get(quandlstock, start_date=startdate, end_date=enddate)\n",
    "    assets.append(stock)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add continuous growth rates to stock info and calculate risk level (sigma) and return rate (drift).  Also, create a list of cgrs, which we'll use to calculate covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigmas = []\n",
    "drifts = []\n",
    "cgrs = []\n",
    "for stock in assets:\n",
    "    price = np.array(stock.Close)\n",
    "    pricep1 = np.roll(price,1)\n",
    "    lnratio = price/pricep1\n",
    "    cgr = np.log(lnratio)\n",
    "    cgr[0]=999.99\n",
    "    stock['cgr'] = cgr\n",
    "    stock = stock[['Close','Volume','cgr']]\n",
    "    \n",
    "    sigma = np.std(cgr[1:])\n",
    "    sigmas.append(sigma)\n",
    "    drift = np.mean(cgr[1:])\n",
    "    drifts.append(drift)\n",
    "    cgrs.append(cgr[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Put cgrs in numpy array and calculate covariances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cgrs = np.array(cgrs)\n",
    "covmat = np.cov(cgrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to normalize weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_weights(weights):\n",
    "    total = np.sum(weights)\n",
    "    return weights/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to calculate risk for a portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def risk(weights):\n",
    "    sig_sq = float(0)\n",
    "    for i in range(len(weights)):\n",
    "        for j in range(len(weights)):\n",
    "            sig_sq += weights[i]*weights[j]*covmat[i][j]\n",
    "    return sig_sq**0.5\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to calculate return of portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_rate(weights):\n",
    "    rate = float(0)\n",
    "    for i in range(len(weights)):\n",
    "        rate += weights[i]*drifts[i]\n",
    "    return rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to generate target distribution samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_samples(num_samples, rate, stddev):\n",
    "    return np.random.normal(loc=rate, scale=stddev, size=num_samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KL Divergence function.  For two normal distributions with std devs $\\sigma_1$ and $\\sigma_2$ and means $\\mu_1$ and $\\mu_2$, the KL Divergence is\n",
    "\n",
    "$KL = \\log\\frac{\\sigma_2}{\\sigma_1} + \\frac{\\sigma_1^2 + (\\mu_1 - \\mu_2)^2}{2\\sigma_2^2} - \\frac{1}{2}$\n",
    "\n",
    "In our function the first term will be called $a$ and the second term $b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def KL(p_rate, p_sig, q_rate, q_sig):\n",
    "    a = np.log(q_sig/p_sig)\n",
    "    b = (p_sig**2 + (p_rate-q_rate)**2)/(2*q_sig**2)\n",
    "    return a + b - 0.5\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to find an upper limit on how good our sharpe ratio can be.  The best return we can have is simply the max of the returns of the individual assets.  The lowest risk is somewhat more difficult to find.  The risk is trickier to find, since the risk is lowered by diversification.  However, an evenly distributed portfolio is a good guess for the minimal risk, since that at least minimizes the $\\pi_i \\pi_j$ term in the summation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_rate = max(drifts)\n",
    "safe_weights = np.array([1.0/len(assets) for i in range(len(assets))])*4\n",
    "target_risk = risk(safe_weights)/4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch function to give us several predictions at once, we calculate the loss for all of them before updating the weight. Note that batch size is set in this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_batch():\n",
    "    batchsize = 100\n",
    "    xbatch = []\n",
    "    #ybatch = make_samples(batchsize, target_rate, target_risk)\n",
    "    for i in range(len(assets)):\n",
    "        xbatch.append(make_samples(batchsize, drifts[i], sigmas[i]))\n",
    "    xbatch = np.column_stack(xbatch)\n",
    "    #return (xbatch, ybatch)\n",
    "    return xbatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to take xbatches and weights and convert to the return of the corresponding portfolio.  Only used in non-rigourous version that allows for shorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_to_returns(xbatch, weights):\n",
    "    returns = []\n",
    "    for x in xbatch:\n",
    "        returns.append(np.dot(x, weights))\n",
    "    return np.array(returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic gradient descent\n",
    "\n",
    "Our input samples will be randomly drawn from the distributions of each of the assets and our output samples will be drawn from our unrealistically optimistic distribution.  \n",
    "\n",
    "Since our target is unattainable, our prediction will never be that close, so we'll use a variable learning rate to help our weights converge.\n",
    "\n",
    "Since we generate our dataset as we go, we'll just do a set number of batches.\n",
    "\n",
    "We'll use KL divergence as our loss, and our target will always be the same, so we never need to take samples from it.\n",
    "\n",
    "This version of the function implements an option which allows shorting of stocks.  However, this means that the minimimum converged to is outside of $S$, so we cannot guarantee its optimality, but it is an interesting result nonetheless.  I wrote this bit of code mostly because it's interesting, but does not represent any rigorous solution.\n",
    "\n",
    "To see the portfolio output by this algorithm, skip the next few cells up until the markdown cell that says \"print out the optimal set of investments\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.654928782158\n",
      "0.0026828937472\n",
      "0.00347499298577\n",
      "0.0277746512176\n",
      "0.038501663077\n",
      "0.00885987680755\n",
      "0.0103785959769\n",
      "0.00289352517287\n",
      "0.0348644859455\n",
      "0.00862830616891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.16818315,  0.06585428,  0.27695607,  0.14180639, -0.03887591,\n",
       "         0.10023291, -0.00672931, -0.03942426, -0.01427736, -0.28224715,\n",
       "         0.03401767,  0.09626012, -0.0932424 ,  0.06365605,  0.06943284,\n",
       "         0.09813273, -0.06658176,  0.02013321,  0.04578597, -0.06411936,\n",
       "         0.05643785,  0.13856044,  0.00705904,  0.14866051,  0.07432828]),\n",
       " 0.071187500308084295)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def optimize_sharpe_with_shorts(batches, learn_rate):\n",
    "    weights = np.random.normal(loc=0.5, scale=0.1, size=len(assets))\n",
    "    weights = weights - np.min(weights)\n",
    "    weights = weights/np.sum(weights)\n",
    "    last_error = float(\"inf\")\n",
    "    for batch in range(batches):\n",
    "        #get a new set of samples\n",
    "        xbatch = next_batch()\n",
    "        \n",
    "        #normalize the weights\n",
    "        norm_weights = weights/np.sum(weights)\n",
    "        \n",
    "        #take stddev and mean of predictions\n",
    "        predictions = batch_to_returns(xbatch, norm_weights)\n",
    "        pred_sig = np.std(predictions)\n",
    "        pred_rate = np.mean(predictions)\n",
    "        \n",
    "        #compare to target using KL div\n",
    "        error = KL(pred_rate, pred_sig, target_rate, target_risk)\n",
    "        \n",
    "        \n",
    "        #get mean of each\n",
    "        means = xbatch.mean(0)\n",
    "        \n",
    "        #update weights\n",
    "        weights += -error*means*learn_rate\n",
    "\n",
    "        #change learning rate\n",
    "        if error/last_error > 1.04:\n",
    "            learn_rate *= 0.7\n",
    "        elif error<last_error:\n",
    "            learn_rate *= 1.05\n",
    "        if batch%1000 == 0:\n",
    "            print(error)\n",
    "  \n",
    "    norm_weights = weights/np.sum(weights)\n",
    "\n",
    "    return (norm_weights, error)\n",
    "\n",
    "(proportions, error) = optimize_sharpe_with_shorts(10000, 0.001)\n",
    "(proportions, error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the formula we calculated for the partial of the divergence with respect to a weight\n",
    "\n",
    "$\\frac{\\partial KL(p,q)}{\\partial \\pi_i} =  - \\frac{\\sum_{j=1}^n \\pi_j \\text{Cov} (R_i, R_j)}{2\\sum_{i,j=1}^n \\pi_i \\pi_j \\text{Cov} (R_i, R_j)} \n",
    " + \\frac{\\sum_{j=1}^n \\pi_j \\text{Cov} (R_i, R_j)}{2\\sigma_2^2} + \\frac{r_j (\\sum_{j=1}^n \\pi_j r_j - \\mu_2)}{\\sigma_2^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now here are some functions to help find the gradient of the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weighted_cov_sum(i, weights):\n",
    "    wsum = float(0)\n",
    "    for j in range(len(weights)):\n",
    "        if j==i:\n",
    "            wsum += 2*weights[i]*covmat[i][i]\n",
    "        else:\n",
    "            wsum += weights[j]*covmat[i][j]\n",
    "    return wsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient(weights):\n",
    "    sig1 = risk(weights)\n",
    "    mu1 = return_rate(weights)\n",
    "    grad = np.zeros(len(weights))\n",
    "    for i in range(len(grad)):\n",
    "        wsum = weighted_cov_sum(i, weights)\n",
    "        grad[i] = (wsum/(2*(target_risk**2))) + ((drifts[i]*mu1)/(target_risk**2)) - (wsum/(2*(sig1**2)))\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the bit of code that does the gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0662823458084\n",
      "0.049399535069\n",
      "0.049399535069\n",
      "0.049399535069\n",
      "0.049399535069\n",
      "0.049399535069\n",
      "0.049399535069\n",
      "0.049399535069\n",
      "0.049399535069\n",
      "0.049399535069\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.05367306,  0.0526857 ,  0.0797929 ,  0.07570606,  0.03559975,\n",
       "         0.05557433,  0.01898776,  0.02772493,  0.02509226,  0.00270994,\n",
       "         0.05636451,  0.04796528,  0.02624322,  0.02964496,  0.05550539,\n",
       "         0.03444939,  0.01608512,  0.04715688,  0.0334907 ,  0.01329721,\n",
       "         0.03980242,  0.04930512,  0.03276941,  0.04934812,  0.04102559]),\n",
       " 0.049399535069029277)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def optimize_sharpe(epochs, learn_rate):\n",
    "    #initialize and normalize weights\n",
    "    weights = np.random.normal(loc=0.5, scale=0.1, size=len(assets))\n",
    "    weights = weights/np.sum(weights)\n",
    "    last_error = float(\"inf\")\n",
    "    for epoch in range(epochs):\n",
    "        #get a new set of samples\n",
    "        xbatch = next_batch()\n",
    "        \n",
    "        #normalize the weights\n",
    "        if np.min(weights)<0:\n",
    "            weights = weights - np.min(weights)\n",
    "        weights = weights/np.sum(weights)\n",
    "        \n",
    "        #take stddev and mean of predictions\n",
    "        pred_sig = risk(weights)\n",
    "        pred_rate = return_rate(weights)\n",
    "        \n",
    "        #compare to target using KL div\n",
    "        error = KL(pred_rate, pred_sig, target_rate, target_risk)\n",
    "        \n",
    "        #get gradient for these weights\n",
    "        grad = gradient(weights)\n",
    "        \n",
    "        #update weights\n",
    "        weights += error*grad*learn_rate\n",
    "        \n",
    "        #change learning rate\n",
    "        if error/last_error > 1.04:\n",
    "            learn_rate *= 0.7\n",
    "        elif error < last_error:\n",
    "            learn_rate *= 1.05\n",
    "        \n",
    "        last_error = error\n",
    "            \n",
    "        if epoch%1000 == 0:\n",
    "            print(error)\n",
    "    \n",
    "    if np.min(weights)<0:\n",
    "        weights = weights-np.min(weights)\n",
    "    weights = weights/np.sum(weights)\n",
    "    #norm_weights = weights/np.sum(weights)\n",
    "\n",
    "    return (weights, error)\n",
    "\n",
    "(proportions, error) = optimize_sharpe(10000, 0.001)\n",
    "(proportions, error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that proportions add up to one.  Note that negative coefficients mean that you should be shorting that asset.  Since you gain capital from short selling a stock, it doesn't matter that the absolute values of all the assets exceeds 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(proportions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the optimal set of investments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portion of portfolio allocated to each asset:\n",
      "MSFT:  0.0536730554101\n",
      "AXP:  0.0526856953144\n",
      "BA:  0.0797929030268\n",
      "CAT:  0.0757060552393\n",
      "CVX:  0.0355997535452\n",
      "CSCO:  0.0555743256241\n",
      "KO:  0.0189877643724\n",
      "DIS:  0.0277249314023\n",
      "XOM:  0.0250922593414\n",
      "GE:  0.00270994189517\n",
      "GS:  0.0563645054395\n",
      "HD:  0.0479652782325\n",
      "IBM:  0.0262432201472\n",
      "JNJ:  0.0296449550162\n",
      "JPM:  0.0555053898548\n",
      "MCD:  0.034449394902\n",
      "MRK:  0.0160851218712\n",
      "NKE:  0.0471568792464\n",
      "PFE:  0.0334906984003\n",
      "PG:  0.0132972093575\n",
      "UTX:  0.0398024198067\n",
      "UNH:  0.0493051240161\n",
      "VZ:  0.0327694141694\n",
      "V:  0.0493481187688\n",
      "WMT:  0.0410255856003\n",
      "Daily risk:  1.00696895367  standard deviation in daily return\n",
      "Daily return:  1.00092837293  daily return\n",
      "Daily Sharpe =  0.994001224448\n",
      "Yearly risk:  11.655160146  standard deviation in percent return\n",
      "Yearly return:  26.3444157505  expected yearly percent return\n"
     ]
    }
   ],
   "source": [
    "print(\"Portion of portfolio allocated to each asset:\")\n",
    "for i in range(len(assets)):\n",
    "    print(stocksymlist[i] + \": \", proportions[i])\n",
    "      \n",
    "portfolio_risk = np.exp(risk(proportions))\n",
    "portfolio_rate = np.exp(return_rate(proportions))\n",
    "print(\"Daily risk: \", portfolio_risk, \" standard deviation in daily return\")\n",
    "print(\"Daily return: \", portfolio_rate, \" daily return\")\n",
    "print(\"Daily Sharpe = \", portfolio_rate/portfolio_risk)\n",
    "\n",
    "yearly_risk = 100*np.exp((252**0.5)*risk(proportions))-100\n",
    "yearly_return = 100*np.exp(252*return_rate(proportions))-100\n",
    "\n",
    "print(\"Yearly risk: \", yearly_risk, \" standard deviation in percent return\")\n",
    "print(\"Yearly return: \", yearly_return, \" expected yearly percent return\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this may seem like an unusually high rate of return, the past year did see a boom in the stock market.  It is also a feasible value, as the fastest growing stock among those we considered grew at a rate of over 100 percent in the past year, as we can see below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0231925872496221"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(target_rate*250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, it makes sense that the benefits of diversification are minimal since there was a booming market and therefore highly correlated stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll print out the risk and return for each of the assets we considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asset Yearly return Yearly risk\n",
      "MSFT 1.00154859643 1.01118173955 0.990473381048\n",
      "AXP 1.0008731209 1.0106197891 0.990355751686\n",
      "BA 1.0028226833 1.01379140046 0.989180498908\n",
      "CAT 1.00204937031 1.01406084974 0.988155070339\n",
      "CVX 1.00003927401 1.01116554448 0.988996588605\n",
      "CSCO 1.00110425046 1.01200094614 0.989232524215\n",
      "KO 1.00015520795 1.00698987563 0.993212774186\n",
      "DIS 0.999805711975 1.01130218913 0.988632006059\n",
      "XOM 0.999807562309 1.00905749424 0.990833097234\n",
      "GE 0.99712137019 1.0152979763 0.982097269435\n",
      "GS 1.0003082679 1.01359411555 0.986892339408\n",
      "HD 1.00097701637 1.01064810846 0.990430801777\n",
      "IBM 0.999445829998 1.01143534893 0.98814603529\n",
      "JNJ 1.00029827614 1.00933014245 0.991051623316\n",
      "JPM 1.00103481984 1.01105355994 0.990090791918\n",
      "MCD 1.00092041607 1.00948933467 0.991511630385\n",
      "MRK 0.99925845976 1.01091519541 0.988469126093\n",
      "NKE 1.00069662025 1.01503680411 0.985872252317\n",
      "PFE 1.00030250223 1.00918838609 0.991195019706\n",
      "PG 0.999508622821 1.00768115165 0.991889767096\n",
      "UTX 1.00069532309 1.01046873326 0.990327845037\n",
      "UNH 1.00136385075 1.01075004798 0.990713631669\n",
      "VZ 0.999869762512 1.01174908899 0.988258623993\n",
      "V 1.00135505008 1.00975600777 0.991680210244\n",
      "WMT 1.00101997603 1.01375452667 0.987438230555\n",
      "Best sharpe of individual stock:  0.993212774186\n"
     ]
    }
   ],
   "source": [
    "print(\"Asset\", \"Yearly return\", \"Yearly risk\")\n",
    "best_sharpe = float(0)\n",
    "for i in range(len(assets)):\n",
    "    sharpe = np.exp(drifts[i])/np.exp(sigmas[i])\n",
    "    if sharpe > best_sharpe:\n",
    "        best_sharpe = sharpe\n",
    "    print(stocksymlist[i], np.exp(drifts[i]), np.exp(sigmas[i]), sharpe)\n",
    "print(\"Best sharpe of individual stock: \", best_sharpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
